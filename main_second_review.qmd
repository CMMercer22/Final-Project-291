---
title: "Impact of Student Socioeconomic Status on School Academic Achievement Scores Within Texas Public and Charter Schools in the 2024-2025 School Year"
author:
  - name: Mercer Mercer
  - name: Nafisa Mohamed
  - name: Catherine Weeks
  - name: Radiah Khan
  
format: pdf
editor: visual
bibliography: references.bib
header-includes:
  - \usepackage{titling}
  - \pretitle{\begin{center}\LARGE\bfseries}
  - \posttitle{\end{center}}
  - \usepackage{titling}
  - \usepackage{etoolbox}
  - \renewcommand{\maketitlehooka}{\centering}
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE
)
```

```{r,include=FALSE}
library(broom)
library(kableExtra)
library(car)
```
# Abstract


  Understanding the extent to which economic inequality affects education quality and accessibility is crucial to making progress towards addressing these issues. While one can assume that economically disadvantaged areas are less likely to have high quality public education, the objective of this paper is to explore specifically if schools in Texas with higher percentages of economically disadvantaged students have lower accountability ratings. This was done by modeling data from the Texas Education Agency’s annual academic accountability ratings. In doing this, we found that the percentage of economically disadvantaged students was a statistically significant predictor of a school’s overall score, while controlling other factors such as the number of students, the academic growth scores, and distinction points. These findings suggest that public and charter schools in Texas with lower overall scores have a higher percentage of economically disadvantaged students, and additionally, schools with higher overall scores tend to have lower percentages of economically disadvantaged students.

\newpage
# Introduction

Through this paper, we aim to address the question: Do schools in Texas with higher percentages of economically disadvantaged students have lower accountability ratings? To address this, we sourced our data from Texas’s annual academic accountability ratings, which it provides for all of its public and charter schools. This question is of particular interest now because the Academic accountability ratings are the benchmark the Texas Education Agency (TEA) uses to take over underperforming districts [pg 100 accountability handbook]. This adds additional questions to what makes a school at risk for being taken over. The previous two districts to be taken over, Houston ISD and Fort Worth ISD, both had a large percentage of economically disadvantaged students. Some districts have begun redrawing their boundaries to avoid government takeovers[cite Texas Tribune]. If schools that predominantly serve economically disadvantaged students are closing to avoid a government takeover, this would cause an undue burden on those students, who would then have to travel further to get to classes, which can already be a barrier to education. Texas has also recently updated the criteria in its accountability rating system, which some teachers and superintendents claim has made earning a passing grade more difficult, potentially affecting whether student economic status influences academic ratings. 
  Previous research has suggested a connection between a student's economic status and school performance. For example, a study from Stanford examining all public school districts in the United States found a strong relationship between district socioeconomic status and average academic achievement [stanford]. Another study found a strong connection between student socioeconomic status and student achievement[second paper]. But neither of these is recent, nor do they use the data that Texas uses to internally select what it considers to be failing schools. Our paper aims to provide additional insight into how Texas’s academic achievement ratings relate to students' socioeconomic status, given the state’s new academic achievement rating system.
  Texas’s academic accountability rating system reports multiple variables containing information on school performance, but the ones of interest to us are as follows: Academic Growth Score, Overall Score, School Progress Score, and multiple variables indicating distinction in particular areas, which we have combined into a single variable that tracks total earned distinctions.



```{r,include=FALSE}
library(readr)
School_Year_2022_2023_Statewide_Accountability_Ratings_20251119 <- read_csv("School_Year_2022-2023_Statewide_Accountability_Ratings_20251119.csv")
#View(School_Year_2022_2023_Statewide_Accountability_Ratings_20251119)
```

```{r,include=FALSE}
library(janitor)
cleaned_name_school <- clean_names(School_Year_2022_2023_Statewide_Accountability_Ratings_20251119)
```

```{r,include=FALSE}
colnames(cleaned_name_school)
```

```{r,include=FALSE}
#Economically disadvantaged grouped by regions 
library(tidyverse)
data <-cleaned_name_school |>
  mutate(percent_economically_disadvantaged = 
           as.numeric(str_replace_all(percent_economically_disadvantaged, "[^0-9.]", "")))
```
```{r,include=FALSE}
filtered_df <- data |>
  filter(grades_served == "09 - 12")
filtered_df
```

```{r,include=FALSE}
filtered_df_pivoted <- filtered_df |>
  pivot_longer(
    cols = starts_with("distinction_"),
    values_to = "distinction_status",
    names_to  = "Distinction Type"
  ) 
filtered_df_pivoted
```
```{r,include=FALSE}
final_df <- filtered_df_pivoted |>
  group_by(campus, district) |>
  summarise(
    number_of_students = first(number_of_students), #to get the unique values
    academic_growth_score = first(academic_growth_score),
    percent_economically_disadvantaged = first(percent_economically_disadvantaged),
    overall_score = first(overall_score),
    school_progress_score = first(school_progress_score),
    distinction_score = sum(distinction_status  == "Earned", na.rm = TRUE),
    .groups = "drop"
  )
final_df

```

\newpage

# Methods

#### Data Source

The data set used in this report is from the Texas Education Agency’s 2025 State, Region, District, and Campus-Level Accountability Report. The data in this report originates from public and charter schools in Texas overseen by the Texas Education Agency (TEA), who are required to submit all student standardized tests and other academic performance data [@texaseducationagency2025]. Each observation in this data set represents a different campus.

Before building our model, we performed some data pre-processing steps to clean and organize the initial data set for analysis:

### Dataset Processing Steps

1.  The dataframe had column names that were either capitalized inconsistently/had multiple spaces in between words; which made parsing the names harder for R to work on. So we cleaned the column names. (e.g., `School Progress Score` $\rightarrow$ `school_progress_score`)

2.  The data was filtered to grades 09-12 using `grades_served` column to keep our results consistent and specific to only high school students.

3.  There were 7 columns of distinction for each school (Distinction ELA/Reading, Distinction Mathematics, Distinction Science, Distinction Soc Studies,Distinction Progress, DIstinction Closing the Gaps, Distinction PostSecondary Readiness). All of them had values of `Earned`, `Not Earned`, `NA`. We reshaped this wide data into long data and merged it into one single column named `distinction_status`.

4.  However, after creating the distinction_status column, each school had seven rows. To prevent this from creating inconsistencies in the results of the chosen model later, we created an additional column, `distinction_score`, which counts the number of times each school earned distinction out of seven and assigns a single score to each school.

5.  We removed all the rows with NA values.

6.  While working on this data set, the numeric variables had their values as characters and not numeric. So we converted them to numeric values for building our model.

The final variables selected for analysis are:

-   `number_of_students`
-   `academic_growth_score`
-   `percent_economically_disadvantaged`
-   `overall_score`
-   `school_progress_score`
-   `distinction_score`
-   `campus`
-   `district`

<center>

#### Data Observations Flow

**Initial dataset:** 10,253 observations

↓

**Filtered to grades 9–12:** 1,394 observations

↓

**After NA removal:** 1,356 observations

</center>

#### Variable Units and Range

The original data contains many variables related to school performance, but in this paper we will focus on schools’ Overall Score, their Academic Growth Scores, their Distinction Scores, the number of students, and the percentage of students who are economically disadvantaged. Before selecting our model, we chose one variable from here as response variable and the rest as explanatory variable.

Table 1: Response Variable Information

| Variable          | Type    | Unit of Observation | Range            |
--------------------|---------|---------------------|------------------|
| Overall Score     | Numeric | School              | 0–100 points     |



Table 2: Explanatory Variable Information


| Variable                           | Type    | Unit of Observation | Range   |
|------------------------------------|---------|---------------------|---------|
| Number of students                 | Numeric | Students            | 1–5,317 |
| Academic growth score              | Numeric | School              | 0–100   |
| Percent economically disadvantaged | Numeric | School              | 0–100%  |
| School progress score              | Numeric | School              | 0–100   |
| Distinction score                  | Numeric | School              | 0–7     |

##### Variable Descriptions

1.  `Overall Score` : This variable represents the school’s final accountability rating on a 0-100 scale. It represents a schoolwide summary of academic performance, progress, and equity. This score is calculated by using three accountability domains: Student Achievement, School Progress, and Closing the Gaps. For this score, 70% is made up of either the Student Achievement or School progress (it picks the “better outcome”) and 30% of it is from their Closing the Gaps domain score (which evaluates how well a school is supporting the performance of specific students, specifically economically disadvantaged students, students from certain racial groups, and special needs students among others). The data handbook further explains how these were specifically calculated [@texaseducationagency2025].

2.  `Academic Growth Score` : This variable is a measure of how much students improved academically over time. It is calculated using a raw growth score which is based on whether students met, exceeded, or fell short of STAAR progress (which is further defined in the data handbook). This raw growth score is then converted to a scaled score using a table, which then becomes the academic growth score, which is also measured on a 0-100 scale.

3.  `Distinction Score` : This variable is derived from the 7 categories of Distinction that schools report. We explained this derivation in our dataset processing steps. But first here is what distinction means across the categories: It is calculated by comparing a school’s performance on multiple indicators to a group of similar campuses. If it places in the top quartile on at least 50% of indicators (for elementary and middle school) or 33% (for high school), it received the distinction. This means that the distinction score is whether or not the school performed exceptionally well compared to similar schools, and is a binary value of 0 (no distinction) or 1 (distinction) across multiple categories. So the distinction score variable sums up the amount of category a school got distinction and reports it on a 0-7 scale.

4.  `Percent economically disadvantaged` : The percentage of students who are economically disadvantaged represents the percentage of students who are economically disadvantaged according to a few criteria. These include eligibility for free and reduced lunch prices and SNAP/TANF participation.

5.  `Number of students` : This variable represents the number of students enrolled in each campus.

6.  `School Progress Score` :

\newpage

#### Model Specification

We will use a nested F test to determine whether the variable Percent Economically Disadvantaged shows a statistically significant difference in the outcome for a school’s overall score. The reduced model contains all variables for determining a school's academic accountability rating, other than Percent Economically Disadvantaged, and the full model contains all variables.

```{r,include=FALSE}
final_df$academic_growth_score <- as.numeric(final_df$academic_growth_score)
final_df$distinction_score <- as.numeric(final_df$distinction_score)
final_df$school_progress_score<- as.numeric(final_df$school_progress_score)
final_df$percent_economically_disadvantaged<- as.numeric(final_df$percent_economically_disadvantaged)
final_df$number_of_students<- as.numeric(final_df$number_of_students)
```

**Reduced model**
$$
\widehat{\text{overall score}}_i =
\beta_0 +
\beta_1 \cdot \text{academic growth score}_i +
\beta_2 \cdot \text{distinction score}_i +
\beta_3 \cdot \text{school progress score}_i + + \beta_4 \cdot \text{number of students}_i
$$

```{r,echo=FALSE}
reduced_model <- lm(
  overall_score ~ academic_growth_score +
    distinction_score + number_of_students+
    school_progress_score,
  data = final_df
)

broom::tidy(reduced_model) |>
  kbl(cbind(), booktabs = T) |>
kable_styling(latex_options = c("striped", "scale_down","hold_position"))|>kable_classic(html_font = "Cambria")
```

**Full model**

$$
\widehat{\text{overall score}}_i
 = \beta_0 + \beta_1 \cdot \text{academic growth score}_i + \beta_2 \cdot \text{distinction score}_i + \beta_3 \cdot \text{school progress score}_i$$ $$+ + \beta_4 \cdot \text{number of students}_i+ \beta_5 \cdot \text{percent economically disadvantaged}_i
$$

```{r,echo=FALSE}
full_model <- 
lm(overall_score ~ academic_growth_score+distinction_score+ school_progress_score + percent_economically_disadvantaged+number_of_students, data = final_df )
broom::tidy(full_model) |>
  kbl(cbind(), booktabs = T) |>
kable_styling(latex_options = c("striped", "scale_down","hold_position"))|>kable_classic(html_font = "Cambria")
```


#### Evaluating assumptions of the model

The four assumptions we need to evaluate are : Linearity, Independence, Normality, Equal Variance.

Assuming independence was maintained, we check the other three conditions. However, we discussed more about the concerns of independence in the discussion section (@sec-discussions)

For checking the linearity and equal variance we check the residual plot of the reduced and full model. See the detailed plot in Appendix A.

For both of the reduced and full model, it violates the linearity, equal variance and normality condition. From the residual plot, we see that it widens as the x gets bigger and there is a pattern above and below y= 0 line. There seems to be unusual points as well which we will investigate later.

In the Q-Q plot, for the both of the model, the points deviates from the reference line. So it does violate the normality condition.

#### Model Selection

To determine the model, we started with calculating the VIF to detect any multicollinearity issues among the explanatory variables. We calculated this using both the reduced and full model. There were no multicollinearity issues given all of the VIFs show little collinearity \< 5 (see Appendix B for detailed results).

We began to test our model using forward model selection with AIC. See Appendix C for detailed results. According to the results,the AIC drops when we add `number of students`, it further drops when we add `percent economically disadvantaged` as well.

To find the influential points, we first filtered the data to find the schools with leverage that was outside of the acceptable range, then further filtered that list to the schools that additionally had a standardized residual that was outside of the range. After filtering, we were left with only five schools that were potential influential points. We refit the model without them and saw no noticeable difference, so we added them back into the final data set. See Appendix D for detailed results.

# Results


## Interpretation of the fitted model
$$
\widehat{\text{overall score}}_i
 = \beta_0 + \beta_1 \cdot \text{academic growth score}_i + \beta_2 \cdot \text{distinction score}_i + \beta_3 \cdot \text{school progress score}_i$$ $$+ + \beta_4 \cdot \text{number of students}_i+ \beta_5 \cdot \text{percent economically disadvantaged}_i
$$


## Interpretation of the relevant co-effecients

$\beta_0$ : Represents our intercept. The intercept is the expected value of the Overall Score when all explanatory variables are zero. In context, when the following coefficients are equal to zero, the school would have an overall score of ~7.16.

$\beta_1$: Indicates the change in the dependent variable overall score for a one-unit change in the corresponding independent variable Academic Growth Score, holding all other variables constant. In context, a 1 point increase in `Academic Growth Score`, there is a ~0.05 decrease in overall score holding all other variables constant.

$\beta_2$: Indicates the change in the dependent variable overall score for a one-unit change in the corresponding independent variable Distinction Score, holding all other variables constant. In our model, 1 point increase in `Distinction Score` would cause a ~0.38 increase in `Overall Score`, holding all other variables constant.

$\beta_3$: Indicates the change in the dependent variable overall score for a one-unit change in the corresponding independent variable school progress score. In context, a one point increase in the school progress score would result in a ~1.02 increase in the overall score holding everything else constant.

$\beta_4$ : Indicates the change in the dependent variable overall score for a one-unit change in the corresponding independent variable Percent economically disadvantaged. A one percent change would result in a 0.09 decrease in the overall score, holding all other variables constant.

$\beta_5$ : Indicates the change in the dependent variable overall score for a one-unit change in the corresponding independent variable Number of students. For every additional student, there is a 0.0002 decrease in the overall score, holding all other variables constant.


## Practical Importance


## Corresponding Confidence Interval


```{r}
vcov(full_model)

```
```{r}
g <- coef(full_model)[1] + coef(full_model)[5]
g_var <- vcov(full_model)[1,1] + vcov(full_model)[5,5] + 2*vcov(full_model)[1,5]
g_se <- sqrt(g_var)
t_stat <- (g- 0)/g_se; as.numeric(t_stat)

```

```{r}
qt(0.975,1255 - 5 -1)
```

```{r}
upper_ci <- (7.07454 + 1.961865*1.76277)
lower_ci <- (7.07454 - 1.961865*1.76277)
lower_ci
upper_ci
```


## Hypothesis test 

The full model contains 5 predictor terms and the reduced model contains 4 predictor terms. We want to see if the additional 1 predictor (percent economically disadvantaged in each school) terms contribute meaningfully to the model. 

$$
H_0:\ \beta_j = 0 \quad \text{for all predictors dropped from the full model}
$$

$$
H_A:\ \beta_j \neq 0 \quad \text{for at least one predictor dropped from the full model}
$$

We will conduct an ANOVA test to do the hypothesis test. 


```{r,echo=FALSE}
anova_test <- anova(reduced_model, full_model) 
kbl(cbind(anova_test), booktabs = T) |>
kable_styling(latex_options = c("striped", "scale_down","hold_position"))|>kable_classic(html_font = "Cambria")

```
We reject the null hypothesis and conclude that we have very strong evidence that the extra term (economically disadvantaged percantage) is necessary (p < 0.05) taking the significance level of 0.05. 

```{r,include=FALSE}
plot_p <- data.frame(
  Predictors = c("Academic Growth Score","Distinction Score","School Progress Score","Percent Economically Disadvantaged", "Number of Students" ),
  P_value = c(0.0000167, 0.0000000, 0.0000000, 0.0000000, 0.0346073)
)

```

```{r, echo=FALSE}
ggplot(plot_p, aes(x = P_value, y = Predictors)) +
  geom_point(size = 2.5, color = "blue") + 
  geom_vline(xintercept = 0.05, color = "red", size = 1) +  
  geom_text(aes(x = 0.05,y = 2.6,label = "Significance threshold (α = 0.05)"),
    angle = 90,vjust = -0.5,color = "black",size = 3) +
  coord_cartesian(xlim = c(0, 0.08)) +  
  labs(
    x = "p-value", 
    y = " ", 
    title = "Significance of Predictors"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.y = element_text(angle = 35, hjust = 1, size = 8),
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16), 
    panel.grid.minor = element_blank()
  )

```

This plot shows us that all of our predictor is lower than 0.05, which is our significance level.



# Discussion {#sec-discussions}

The goal of this study was to address the question whether schools in Texas with higher percentages of economically disadvantaged students have lower accountability ratings. Some things should be considered before drawing any conclusions from this model. First, one potential issue with this model is a violation of independence among the variables. Because the Overall Score variable is calculated using some of the metrics within the explanatory variables, we have some concern about this model's independence. However, one of the strengths of this study was a very low VIC and AIC across all variables. So we are somewhat confident that this should not be a major problem, as it indicates the variables are not collinear. Another thing to consider is that this data is only from one year, and it is very difficult to build a dataset with longer term data due to Texas’s constant fluctuations in how it reports and calculates the same data across many years. Next, the major strength of this study is that the model performs very well and yields statistically significant results. Finally, the conclusions drawn from this should also only be used to form conclusions about public and charter schools within Texas in the academic year 2024-2025. This is because the metrics used to create many of the variables tested are specific to Texas’s academic measurements, such as the STAAR test, and cannot easily be compared with those of other States, and the data used is limited to only Texas public and charter schools.

\newpage

# Appendix {.appendix}

## Appendix A: Conditions of the linear regression model {#sec-conditions}

We explored the residual and Q-Q plot of both of the model to see if it violates the linearity, nornmality and equal variance condition.

```{r,echo=FALSE}
par(mfrow = c(1, 2))
plot(reduced_model, which = 1)
plot(reduced_model, which = 2)
mtext("Diagnostic Plots for the Reduced Model", 
      side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
par(mfrow = c(1, 1))
```

```{r,echo=FALSE}
par(mfrow = c(1, 2))
plot(full_model, which = 1)
plot(full_model, which = 2)
mtext("Diagnostic Plots for the Full Model", 
      side = 3, line = -2, outer = TRUE, cex = 1.2, font = 2)
par(mfrow = c(1, 1))
```

## Appendix B: VIF {#sec-vif}

Checking the VIF for the full model.

```{r,echo=FALSE}
vif(full_model)
```

## Appendix C: Stepwise AIC {#sec-aic}

Checking to see how adding additional parameters affect AIC.

```{r,echo=FALSE}
add1(reduced_model,
     scope = ~ number_of_students +
              academic_growth_score +
              percent_economically_disadvantaged +
              school_progress_score +
              distinction_score,
     test = "F")
```

## Appendix D: Influential Points {#sec-influential}

This is the result of the summary table after we removed the points. As we can see the conclusion does not change.

```{r,include=FALSE}
influence <- augment(full_model)
influence <- influence |> mutate(row_id = row_number())

```

```{r,include=FALSE}
k_plus_one <- length(coef(full_model))
n <- nrow(final_df)

# Filtering the data to view observations with high leverage
influence |> filter(.hat > 2 * k_plus_one/n)
leverage_index <- influence |> filter(.hat > 2 * k_plus_one/n) |> select(row_id) |> pull()
save <- final_df[leverage_index,]
augment_df<-influence[leverage_index,]

save$row_id <- leverage_index

augment_df<- augment_df |> left_join(save|>select(campus, district,row_id), join_by("row_id"=="row_id"))

```

```{r,include=FALSE}
##std residuals
augment_df1<-augment_df |> filter(.std.resid < -2 | .std.resid > 2)
std_resid_id <- augment_df |> filter(.std.resid < -2 | .std.resid > 2) |> select(row_id) |> pull()
```

```{r,include=FALSE}
#removing the influential datapoints 
final_df <-final_df[-1130,]
final_df <-final_df[-892,]
final_df <-final_df[-389, ]
final_df <-final_df[-333, ]
```

```{r,include=FALSE}
#refitting the datapoints 
new_model <- lm(overall_score ~ academic_growth_score+distinction_score+ school_progress_score + percent_economically_disadvantaged+number_of_students, data = final_df )
summary(new_model)
```

```{r,echo=FALSE}
#the refitted linear regression summary  
reduced_model_logged <-
  lm(overall_score ~ academic_growth_score+distinction_score+ school_progress_score, data = final_df )
summary(reduced_model_logged)
```

